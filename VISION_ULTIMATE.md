# ğŸ›ï¸ CEREBRUM ULTIMATE - Refinaria Suprema de Conhecimento

> **"Do caos Ã  harmonia: Um laboratÃ³rio inteligente de conhecimento curado"**

---

## ğŸ¯ A VISÃƒO SUPREMA

**VOCÃŠ JOGA:** Caos informacional (PDFs, artigos, notas soltas, ideias fragmentadas)

**SISTEMA RETORNA:** Conhecimento cristalino, perfeitamente organizado, densamente interconectado, pronto para uso, crescendo harmonicamente

### O Que Isso Significa?

Um **sistema multi-agente orquestrado** que combina os melhores frameworks de gestÃ£o de conhecimento:

- **BASB (Building a Second Brain)**: CODE + PARA + Progressive Summarization
- **LYT (Linking Your Thinking)**: MOCs + Fluid Frameworks
- **Zettelkasten**: Atomic notes + Evergreen thinking
- **PENSE Framework**: Metodologia d.IA.logo
- **PKM Best Practices**: Johnny Decimal, LIFT, etc.

**Resultado:** Um segundo cÃ©rebro que nÃ£o apenas armazena, mas **pensa, conecta, evolui e cria** junto com vocÃª.

---

## ğŸ§  METÃFORA CENTRAL

### O Cerebrum Ã© um **LaboratÃ³rio AnatÃ´mico de Conhecimento**

Imagine um laboratÃ³rio onde:

1. **MatÃ©ria-prima bruta** (PDFs, textos) entra
2. **Anatomistas especializados** (agentes) dissecam e analisam
3. **Processos quÃ­micos** (algoritmos) refinam e purificam
4. **Taxonomistas** etiquetam e classificam
5. **Conectores neurais** criam sinapses entre conceitos
6. **Curadores** mantÃªm saÃºde do sistema
7. **Sintetizadores** geram insights emergentes

**Output:** Conhecimento de grau farmacÃªutico, pronto para consumo cognitivo.

---

## ğŸ—ï¸ ARQUITETURA DE INTEGRAÃ‡ÃƒO DOS FRAMEWORKS

### Camada 1: **BASB (FundaÃ§Ã£o Organizacional)**

**O que traz:**
- **PARA Structure**: Projects, Areas, Resources, Archives
- **CODE Workflow**: Capture, Organize, Distill, Express
- **Progressive Summarization**: Layers 0-4
- **Intermediate Packets**: Building blocks reutilizÃ¡veis

**Como integra:**
```
00-Inbox/           â†’ CAPTURE (raw)
â”œâ”€ 1-Projects/      â†’ ORGANIZE (ativo)
â”œâ”€ 2-Areas/         â†’ ORGANIZE (contÃ­nuo)
â”œâ”€ 3-Resources/     â†’ ORGANIZE (referÃªncia)
â””â”€ 4-Archives/      â†’ ORGANIZE (inativo)

03-Permanent/       â†’ DISTILL + EXPRESS (evergreen)
04-MOCs/            â†’ EXPRESS (mapas)
05-IPs/             â†’ EXPRESS (packets)
```

---

### Camada 2: **LYT (Estrutura de Pensamento)**

**O que traz:**
- **MOCs (Maps of Content)**: Ãndices dinÃ¢micos temÃ¡ticos
- **Fluid Frameworks**: Estruturas flexÃ­veis nÃ£o-hierÃ¡rquicas
- **Home Note**: Ponto central de navegaÃ§Ã£o
- **Emergence**: Estrutura emerge do uso

**Como integra:**
```
04-MOCs/
â”œâ”€ ğŸ  HOME.md                    â† Entry point
â”œâ”€ ğŸ§  Neuroscience MOC.md
â”œâ”€ ğŸ“š Philosophy MOC.md
â””â”€ ğŸ”¬ Research Methods MOC.md

Cada MOC:
- Agrupa notas relacionadas
- Cria narrativas temÃ¡ticas
- Evolui organicamente
- Links bidirecionais automÃ¡ticos
```

**Tipos de MOCs:**
1. **Discipline MOCs**: Por domÃ­nio (NeurociÃªncia, Filosofia)
2. **Project MOCs**: Por projeto ativo
3. **Concept MOCs**: Por conceito central (Plasticidade, Aprendizagem)
4. **Time MOCs**: Por perÃ­odo (2025-Q1 Learning)

---

### Camada 3: **Zettelkasten (Atomicidade e ConexÃµes)**

**O que traz:**
- **Atomic Notes**: 1 conceito = 1 nota
- **Permanent Notes**: Pensamento evergreen
- **Literature Notes**: Captura de fontes
- **Fleeting Notes**: Ideias rÃ¡pidas
- **Slip-box Method**: ConexÃµes emergentes

**Como integra:**
```
01-Fleeting/           â†’ Ideias rÃ¡pidas (<24h)
02-Literature/         â†’ Notas de fontes
03-Permanent/          â†’ Notas atÃ´micas evergreen
  â”œâ”€ Cada nota:
  â”‚   â€¢ TÃ­tulo semÃ¢ntico
  â”‚   â€¢ ID Ãºnico (YYYYMMDDHHMMSS)
  â”‚   â€¢ Tags hierÃ¡rquicas
  â”‚   â€¢ Links para 3-8 notas
  â”‚   â€¢ Status (seedlingâ†’evergreen)
```

**PrincÃ­pios Zettelkasten:**
- **Atomicidade**: Nota = 1 ideia completa
- **Autonomia**: Nota faz sentido sozinha
- **Conectividade**: Sempre link 3+ outras notas
- **Desenvolvimento**: Notas evoluem ao longo do tempo

---

### Camada 4: **PENSE Framework (Metodologia ProprietÃ¡ria)**

**O que traz:**
- **P**recisÃ£o: ComunicaÃ§Ã£o clara e especÃ­fica
- **E**strutura: OrganizaÃ§Ã£o sistemÃ¡tica
- **N**atureza: AdaptaÃ§Ã£o ao contexto brasileiro
- **S**istematizaÃ§Ã£o: Processos replicÃ¡veis
- **E**xperimentaÃ§Ã£o: IteraÃ§Ã£o contÃ­nua

**Como integra:**
```yaml
# Frontmatter padrÃ£o PENSE
---
title: "Conceito X"
pense:
  precisao: "DefiniÃ§Ã£o clara e objetiva"
  estrutura: "MOC â†’ Permanent â†’ Literatura"
  natureza: "Contexto brasileiro aplicÃ¡vel"
  sistematizacao: "Template aplicado: concept-academic"
  experimentacao: "VersÃ£o 3, iterado 2x"
---
```

---

### Camada 5: **PKM Best Practices (OtimizaÃ§Ãµes)**

**Johnny Decimal:**
```
10-19 Meta Sistema
  11 Templates
  12 Workflows
  13 Dashboards

20-29 Projetos Ativos
  21 Projeto A
  22 Projeto B

30-39 Ãreas de Responsabilidade
  31 Pesquisa
  32 Ensino
  33 Consultoria

40-49 Recursos por DomÃ­nio
  41 NeurociÃªncia
  42 Filosofia
  43 Sistemas Complexos

50-59 Arquivos
```

**LIFT (Levels of Importance for Filtering):**
- **Level 1**: CrÃ­tico (preciso hoje)
- **Level 2**: Importante (preciso esta semana)
- **Level 3**: Ãštil (preciso este mÃªs)
- **Level 4**: Interessante (algum dia)

---

## ğŸ¤– SISTEMA DE AGENTES ORQUESTRADOS

### Orquestrador: **ATHENA (Claude Code)**

**FunÃ§Ã£o:** Maestro que coordena todos os agentes baseado em POPs

**Responsabilidades:**
1. Recebe input do usuÃ¡rio (arquivo, comando, tarefa)
2. Analisa tipo de trabalho necessÃ¡rio
3. Cria **plano de execuÃ§Ã£o** (workflow)
4. Chama agentes na ordem correta
5. Valida outputs entre etapas
6. Gera relatÃ³rio final

**Interface:**
```bash
# UsuÃ¡rio interage com ATHENA
cerebrum process paper.pdf

# ATHENA decide o workflow:
# 1. Extrator â†’ 2. Classificador â†’ 3. Destilador â†’
# 4. Anatomista â†’ 5. Conector â†’ 6. Curador â†’ 7. Relator
```

---

### Agente 1: **EXTRATOR (Input Processor)**

**FunÃ§Ã£o:** Converte qualquer input em texto estruturado

**Inputs aceitos:**
- PDF (acadÃªmico, livro, artigo)
- Markdown, HTML, TXT
- EPUB, DOCX
- Imagens (OCR)
- Ãudio/vÃ­deo (transcriÃ§Ã£o)
- URLs (web scraping)

**Output:**
```json
{
  "raw_text": "...",
  "metadata": {
    "source_type": "pdf",
    "title": "...",
    "authors": ["..."],
    "date": "...",
    "length_words": 5420,
    "language": "pt-BR"
  },
  "structure": {
    "sections": [...],
    "headings": [...],
    "citations": [...]
  }
}
```

**POP (Procedimento Operacional PadrÃ£o):**
```
1. Detectar tipo de arquivo
2. Aplicar parser apropriado
3. Extrair metadata (tÃ­tulo, autor, data)
4. Identificar estrutura (seÃ§Ãµes, headings)
5. Normalizar encoding (UTF-8)
6. Output: JSON estruturado
7. ValidaÃ§Ã£o: texto extraÃ­do > 100 palavras?
```

---

### Agente 2: **CLASSIFICADOR (Framework Decider)**

**FunÃ§Ã£o:** Decide qual combinaÃ§Ã£o de frameworks aplicar

**LÃ³gica de decisÃ£o:**
```python
def classify(input_data):
    # Analisa tipo de conteÃºdo
    content_type = detect_type(input_data)

    if content_type == "academic_paper":
        return {
            "basb": "Resources â†’ Literature",
            "lyt": "Create Discipline MOC",
            "zettelkasten": "Literature + Permanent notes",
            "templates": ["academic-literature", "concept"]
        }

    elif content_type == "book_chapter":
        return {
            "basb": "Resources",
            "lyt": "Add to Book MOC",
            "zettelkasten": "Permanent notes only",
            "templates": ["book-note", "concept"]
        }

    elif content_type == "fleeting_idea":
        return {
            "basb": "Inbox â†’ quick capture",
            "lyt": "Link to relevant MOC",
            "zettelkasten": "Fleeting â†’ convert to Permanent if valuable",
            "templates": ["fleeting"]
        }
```

**Output:**
```json
{
  "framework_plan": {
    "basb_path": "3-Resources/41-Neuroscience/",
    "lyt_mocs": ["Neuroscience MOC", "Learning MOC"],
    "zettelkasten_type": "literature",
    "templates": ["academic-literature", "concept"],
    "taxonomy": {
      "domain": "neuroscience",
      "subdomain": "plasticity",
      "tags": ["neuro/cellular", "research/empirical"]
    }
  }
}
```

---

### Agente 3: **DESTILADOR (Knowledge Atomizer)**

**FunÃ§Ã£o:** Quebra conteÃºdo em notas atÃ´micas seguindo princÃ­pios Zettelkasten + BASB

**Process:**
```
1. AnÃ¡lise semÃ¢ntica (LLM)
   â†“
2. Identificar conceitos atÃ´micos (5-15 por documento)
   â†“
3. Para cada conceito:
   a. Extrair contexto relevante
   b. Criar definiÃ§Ã£o standalone
   c. Identificar relaÃ§Ãµes com outros conceitos
   â†“
4. Aplicar template apropriado
   â†“
5. Progressive Summarization Layer 0 (texto completo)
```

**Output por conceito:**
```markdown
---
id: 20250115143022
title: "PotenciaÃ§Ã£o de Longo Prazo (LTP)"
type: permanent
status: seedling
source: "Silva2024_Neuroplasticity"
domain: neuroscience
subdomain: cellular
tags:
  - neuro/cellular
  - neuro/synaptic
  - concept/mechanism
links_out: []  # SerÃ¡ preenchido pelo Conector
links_in: []
basb:
  para: "3-Resources/41-Neuroscience"
  progressive_summary: 0
lyt:
  mocs: ["Neuroscience MOC", "Learning MOC"]
zettelkasten:
  type: permanent
  connections: 0  # SerÃ¡ atualizado
created: 2025-01-15T14:30:22
modified: 2025-01-15T14:30:22
---

# PotenciaÃ§Ã£o de Longo Prazo (LTP)

> [!abstract] DefiniÃ§Ã£o AtÃ´mica
> LTP Ã© o fortalecimento duradouro de sinapses baseado em padrÃµes recentes de atividade neuronal, considerado o mecanismo celular fundamental da aprendizagem e memÃ³ria.

## ğŸ§¬ EssÃªncia do Conceito

[ConteÃºdo destilado...]

## ğŸ”— ConexÃµes (a serem preenchidas)

## ğŸ“š Source

Silva, M. & Costa, P. (2024). Neuroplasticity and Learning. *Nature Neuroscience*.
```

**POP:**
```
1. LLM: Identificar 5-15 conceitos atÃ´micos
2. Para cada conceito:
   a. Validar atomicidade (1 ideia clara?)
   b. Extrair contexto (3-5 parÃ¡grafos relevantes)
   c. Gerar definiÃ§Ã£o (1-2 frases)
   d. Aplicar template
   e. Slugify tÃ­tulo â†’ filename
3. ValidaÃ§Ã£o:
   âœ“ Cada nota tem tÃ­tulo Ãºnico?
   âœ“ DefiniÃ§Ã£o Ã© standalone?
   âœ“ Frontmatter completo?
4. Output: Array de notas atÃ´micas
```

---

### Agente 4: **ANATOMISTA (Template Applier & Structure Designer)**

**FunÃ§Ã£o:** Aplica templates dinÃ¢micos e cria estrutura interna perfeita

**Templates disponÃ­veis:**

#### **1. Concept Note (Permanent)**
```markdown
---
[frontmatter]
---

# {title}

> [!abstract] DefiniÃ§Ã£o
> {atomic_definition}

## ğŸ¯ EssÃªncia

{core_explanation}

## ğŸ” Detalhamento

### Componentes
{components}

### Mecanismos
{mechanisms}

## ğŸŒ ConexÃµes

### Fundamenta
{supports_what}

### Ã‰ fundamentado por
{supported_by}

### Relaciona-se com
{related_to}

### Contrasta com
{contrasts_with}

## ğŸ’¡ AplicaÃ§Ãµes

{practical_applications}

## ğŸ“Š EvidÃªncias

{evidence}

## â“ QuestÃµes Abertas

{open_questions}

## ğŸ“š Fontes

{sources}

---

**Status:** {status_emoji} {status}
**PrÃ³xima RevisÃ£o:** {next_review}
**VersÃ£o:** {version}
```

#### **2. Literature Note**
```markdown
---
[frontmatter]
---

# ğŸ“š {title}

> [!info] InformaÃ§Ã£o BibliogrÃ¡fica
> **Autores:** {authors}
> **Ano:** {year}
> **PublicaÃ§Ã£o:** {publication}
> **DOI:** {doi}
> **Tags:** {tags}

## ğŸ¯ Pergunta de Pesquisa

{research_question}

## ğŸ“‹ Resumo Executivo

{executive_summary}

## ğŸ”‘ Argumentos Principais

{main_arguments}

## ğŸ“Š Metodologia

{methodology}

## ğŸ’ Achados Principais

{findings}

## ğŸ’­ AnÃ¡lise CrÃ­tica

> [!question] QuestÃµes Levantadas
> {critical_questions}

## ğŸ”— Conceitos ExtraÃ­dos

{permanent_notes_created}

## ğŸ“ Notas Pessoais

{personal_insights}

---

**Progressive Summary:**
- Layer 1: {highlights_count} destaques
- Layer 2: {key_points_count} pontos-chave
- Layer 3: {executive_summary_created}
```

#### **3. Project Note (BASB)**
```markdown
---
[frontmatter]
---

# ğŸ¯ {project_name}

> [!tip] Status
> **Fase:** {phase}
> **Prazo:** {deadline}
> **Progresso:** {progress}%

## ğŸ¯ Objetivo

{clear_outcome}

## ğŸ“‹ Escopo

### Entregas
{deliverables}

### NÃ£o-Escopo
{out_of_scope}

## ğŸ—ºï¸ Roadmap

{milestones}

## ğŸ“¦ Intermediate Packets Criados

{ips_generated}

## ğŸ”— Recursos Relacionados

### Notas Permanentes
{permanent_notes}

### Literatura
{literature}

### MOCs
{mocs}

## ğŸ“ Log de Progresso

{progress_log}

## âœ… Checklist de FinalizaÃ§Ã£o

{completion_checklist}
```

#### **4. MOC (LYT)**
```markdown
---
[frontmatter]
---

# ğŸ—ºï¸ {moc_title}

> [!map] Mapa de ConteÃºdo
> Este MOC organiza conhecimento sobre **{topic}**.
> Ãšltima atualizaÃ§Ã£o: {last_updated}

## ğŸŒŸ Conceitos Centrais

{core_concepts}

## ğŸŒ³ Hierarquia Conceitual

```mermaid
graph TD
    A[{root_concept}] --> B[{sub1}]
    A --> C[{sub2}]
    B --> D[{leaf1}]
```

## ğŸ“š Literatura Fundamental

{key_literature}

## ğŸ”¬ TÃ³picos Relacionados

### Sub-tÃ³pico 1
{subtopic_notes}

### Sub-tÃ³pico 2
{subtopic_notes}

## ğŸ¯ Projetos Usando Este Conhecimento

{related_projects}

## ğŸŒŠ Fluxo de Aprendizado Recomendado

1. {learning_path}

## ğŸ”— MOCs Relacionados

{related_mocs}

## ğŸ“Š EstatÃ­sticas

- Total de notas: {count}
- Densidade de conexÃµes: {density}
- Status: {health}
```

**POP do Anatomista:**
```
1. Receber nota do Destilador
2. Identificar tipo (concept, literature, project, moc)
3. Selecionar template apropriado
4. Enriquecer com seÃ§Ãµes especÃ­ficas:
   - Callouts (abstract, tip, question, etc.)
   - Mermaid diagrams (quando aplicÃ¡vel)
   - Dataview queries (quando aplicÃ¡vel)
   - Tabelas comparativas
   - Listas de verificaÃ§Ã£o
5. Aplicar Progressive Summarization Layer 0
6. ValidaÃ§Ã£o estrutural:
   âœ“ Todas seÃ§Ãµes obrigatÃ³rias presentes?
   âœ“ Markdown vÃ¡lido?
   âœ“ Frontmatter completo?
7. Output: Nota estruturada completa
```

---

### Agente 5: **CONECTOR (Semantic Linker)**

**FunÃ§Ã£o:** Cria conexÃµes inteligentes entre notas usando mÃºltiplas estratÃ©gias

**EstratÃ©gias de Linking:**

#### **1. Semantic Similarity (Embeddings)**
```python
# Gera embedding de cada nota
embedding = model.encode(note.content)

# Busca notas similares
similar = vector_db.search(embedding, k=20, threshold=0.7)

# Filtra por contexto
for candidate in similar:
    if should_link(note, candidate):
        create_link(note, candidate, type="related", confidence=score)
```

#### **2. Concept Hierarchy (Taxonomia)**
```python
# Analisa taxonomia
note.tags = ["neuro/cellular", "concept/mechanism"]

# Encontra notas no mesmo domÃ­nio
same_domain = find_by_tag("neuro/*")

# Identifica relaÃ§Ãµes hierÃ¡rquicas
if is_child(note, parent_note):
    create_link(note, parent, type="prerequisite")
elif is_parent(note, child_note):
    create_link(note, child, type="supports")
```

#### **3. Citation Analysis**
```python
# Notas de literatura que citam as mesmas fontes
if shares_citations(note_a, note_b, min_overlap=2):
    create_link(note_a, note_b, type="co-cited")
```

#### **4. LLM-Based Contextual**
```python
# Para conexÃµes nÃ£o-Ã³bvias
llm_analysis = llm.analyze_connection(note_a, note_b)

if llm_analysis.should_link:
    create_link(
        note_a, note_b,
        type=llm_analysis.relationship,  # "supports", "extends", "applies", etc.
        confidence=llm_analysis.confidence
    )
```

**Tipos de Links:**
- `supports`: B fornece evidÃªncia para A
- `extends`: B expande/desenvolve A
- `applies`: B Ã© aplicaÃ§Ã£o prÃ¡tica de A
- `prerequisite`: A deve ser entendido antes de B
- `contrasts`: A e B oferecem visÃµes opostas
- `related`: ConexÃ£o geral
- `exemplifies`: B Ã© exemplo de A
- `analogous`: A e B tÃªm estrutura similar

**Output:**
```markdown
## ğŸ”— ConexÃµes Inteligentes

### Fundamenta
- [[ConsolidaÃ§Ã£o de MemÃ³ria]] (supports, 0.92) - LTP Ã© mecanismo da consolidaÃ§Ã£o
- [[Aprendizagem Espacial]] (supports, 0.88) - LTP crÃ­tico para mapas cognitivos

### Ã‰ Fundamentado Por
- [[Receptores NMDA]] (prerequisite, 0.95) - AtivaÃ§Ã£o NMDA inicia LTP
- [[Influxo de CÃ¡lcio]] (prerequisite, 0.90) - CaÂ²âº Ã© mensageiro do LTP

### Relacionados
- [[DepressÃ£o de Longo Prazo (LTD)]] (contrasts, 0.85) - Processo oposto
- [[Plasticidade SinÃ¡ptica]] (related, 0.90) - Conceito mais amplo

### AplicaÃ§Ãµes
- [[Treino Cognitivo]] (applies, 0.80) - LTP pode ser modulado por treino
- [[Neurofarmacologia]] (applies, 0.75) - Drogas que afetam LTP
```

**POP do Conector:**
```
1. Receber conjunto de notas novas
2. Gerar embeddings (cache para reuso)
3. Para cada nota nova:
   a. Buscar candidatas (embeddings + taxonomia)
   b. AnÃ¡lise LLM dos top 10 candidatos
   c. Criar links com tipo e confidence
   d. Atualizar backlinks nas notas linkadas
4. Detectar clusters:
   - Se 5+ notas formam cluster denso â†’ sugerir MOC
5. AnÃ¡lise de grafo:
   - Identificar notas "hub" (centralidade alta)
   - Detectar "knowledge gaps" (conceitos mencionados mas sem nota)
6. ValidaÃ§Ã£o:
   âœ“ Cada nota tem 3-8 links?
   âœ“ Notas Ã³rfÃ£s < 5%?
   âœ“ DistribuiÃ§Ã£o de tipos de links balanceada?
7. Output: Grafo atualizado + sugestÃµes de MOCs
```

---

### Agente 6: **CURADOR (Vault Health Manager)**

**FunÃ§Ã£o:** ManutenÃ§Ã£o contÃ­nua e evoluÃ§Ã£o do sistema

**Responsabilidades:**

#### **1. Health Checks**
```python
def vault_health_check():
    metrics = {
        "total_notes": count_all_notes(),
        "orphan_notes": find_orphans(),  # <3% target
        "average_links": calculate_avg_links(),  # 3-8 target
        "status_distribution": {
            "seedling": count_by_status("seedling"),
            "budding": count_by_status("budding"),
            "evergreen": count_by_status("evergreen")
        },
        "progressive_summary": {
            "layer_0": count_by_ps_layer(0),
            "layer_1": count_by_ps_layer(1),
            "layer_2": count_by_ps_layer(2),
            "layer_3": count_by_ps_layer(3)
        },
        "stale_notes": find_stale(days=90),  # NÃ£o revisadas hÃ¡ 90 dias
        "duplicates": find_potential_duplicates(threshold=0.95)
    }

    return generate_health_report(metrics)
```

#### **2. Spaced Repetition Scheduling**
```python
def schedule_reviews():
    for note in all_notes:
        if note.status == "seedling":
            note.next_review = now() + days(7)
        elif note.status == "budding":
            note.next_review = now() + days(14)
        elif note.status == "evergreen":
            note.next_review = now() + days(30)

        # Ajuste baseado em uso
        if note.access_count_30d > 10:
            note.next_review = sooner(note.next_review)
```

#### **3. Status Evolution**
```python
def evolve_note_status(note):
    criteria = {
        "seedling_to_budding": {
            "min_links": 3,
            "min_reviews": 1,
            "has_ps_layer_1": True
        },
        "budding_to_evergreen": {
            "min_links": 5,
            "min_reviews": 3,
            "has_ps_layer_2": True,
            "age_days": 30
        }
    }

    if note.status == "seedling" and meets_criteria(note, "seedling_to_budding"):
        note.status = "budding"
        note.version += 1

    elif note.status == "budding" and meets_criteria(note, "budding_to_evergreen"):
        note.status = "evergreen"
        note.confidence = 0.95
```

#### **4. Duplicate Detection & Merge**
```python
def handle_duplicates():
    duplicates = find_potential_duplicates(threshold=0.90)

    for pair in duplicates:
        similarity = calculate_similarity(pair[0], pair[1])

        if similarity > 0.95:
            # Sugerir merge
            suggestions.append({
                "action": "merge",
                "note_a": pair[0],
                "note_b": pair[1],
                "confidence": similarity,
                "strategy": "keep_more_linked"
            })
```

**Dashboard Gerado:**
```markdown
# ğŸ“Š Vault Health Dashboard
*Gerado: 2025-01-15 14:30*

## ğŸ¯ MÃ©tricas Gerais

| MÃ©trica | Valor | Target | Status |
|---------|-------|--------|--------|
| Total de Notas | 1,243 | - | - |
| Notas Ã“rfÃ£s | 18 (1.4%) | <3% | âœ… |
| MÃ©dia de Links | 4.8 | 3-8 | âœ… |
| Densidade do Grafo | 0.42 | >0.3 | âœ… |

## ğŸŒ± DistribuiÃ§Ã£o de Status

```chart
type: pie
labels: [Seedling, Budding, Evergreen]
data: [652, 398, 193]
```

- ğŸŒ± Seedling: 652 (52%)
- ğŸŒ¿ Budding: 398 (32%)
- ğŸŒ³ Evergreen: 193 (16%)

**Objetivo:** 20% Evergreen em 6 meses

## ğŸ“ˆ Progressive Summarization

| Layer | Notas | % |
|-------|-------|---|
| Layer 0 (raw) | 823 | 66% |
| Layer 1 (bold) | 298 | 24% |
| Layer 2 (highlight) | 98 | 8% |
| Layer 3 (summary) | 24 | 2% |

## âš ï¸ AÃ§Ãµes Recomendadas

### Urgente
1. **18 notas Ã³rfÃ£s** precisam de links
   - Executar: `cerebrum link --orphans-only`

2. **45 notas nÃ£o revisadas** hÃ¡ >90 dias
   - Agenda revisÃ£o: prÃ³ximos 7 dias

### Importante
3. **3 pares de duplicatas** detectados (>90% similaridade)
   - Revisar manualmente para merge

4. **12 knowledge gaps** identificados
   - Conceitos mencionados mas sem nota dedicada

## ğŸ“… PrÃ³ximas RevisÃµes (7 dias)

| Data | Notas Agendadas | Tempo Estimado |
|------|-----------------|----------------|
| 2025-01-16 | 8 | 40 min |
| 2025-01-17 | 12 | 60 min |
| 2025-01-18 | 5 | 25 min |

## ğŸ† Conquistas Este MÃªs

- âœ… 87 notas criadas
- âœ… 234 novos links
- âœ… 23 notas evoluÃ­ram para Evergreen
- âœ… 5 MOCs criados

## ğŸ“Š TendÃªncias (vs mÃªs anterior)

- CriaÃ§Ã£o: +45% â†—ï¸
- Linking: +120% â†—ï¸
- RevisÃµes: +30% â†—ï¸
```

**POP do Curador:**
```
ExecuÃ§Ã£o DiÃ¡ria (5 min):
1. Scan notas criadas hoje
2. Validar frontmatter
3. Verificar orphans imediatos
4. Agendar prÃ³ximas revisÃµes

ExecuÃ§Ã£o Semanal (20 min):
1. Gerar health report
2. Detectar duplicatas
3. Evoluir status de notas elegÃ­veis
4. Sugerir MOCs para clusters

ExecuÃ§Ã£o Mensal (60 min):
1. Dashboard completo
2. AnÃ¡lise de tendÃªncias
3. Limpeza de archives
4. OtimizaÃ§Ã£o de taxonomia
5. Backup + versionamento

ValidaÃ§Ã£o ContÃ­nua:
âœ“ Orphan rate < 3%?
âœ“ Avg links 3-8?
âœ“ Evergreen ratio crescendo?
âœ“ PS layers distribuÃ­das?
```

---

### Agente 7: **SINTETIZADOR (Emergent Insight Generator)**

**FunÃ§Ã£o:** Detectar padrÃµes cross-domain e gerar conhecimento emergente

**EstratÃ©gias:**

#### **1. Cluster Analysis**
```python
def detect_knowledge_clusters():
    # Graph community detection
    communities = louvain_algorithm(knowledge_graph)

    for community in communities:
        if len(community) > 8:  # Cluster significativo
            analyze_cluster(community)
```

#### **2. Cross-Domain Pattern Detection**
```python
def find_analogies():
    # Busca padrÃµes estruturais similares em domÃ­nios diferentes
    patterns = []

    for domain_a in domains:
        for domain_b in domains:
            if domain_a != domain_b:
                structural_similarity = compare_structures(domain_a, domain_b)

                if structural_similarity > 0.75:
                    patterns.append({
                        "domains": [domain_a, domain_b],
                        "pattern": extract_pattern(domain_a, domain_b),
                        "confidence": structural_similarity
                    })
```

**Exemplo de Insight Emergente:**
```markdown
# ğŸ”® Insight Emergente: Meta-PadrÃ£o de AdaptaÃ§Ã£o Evolutiva

> [!insight] Descoberta
> Analisando o vault, identifiquei o mesmo padrÃ£o estrutural em 3 domÃ­nios distintos:
> - [[Neuroplasticidade]] (NeurociÃªncia)
> - [[Sistemas Adaptativos Complexos]] (Teoria de Sistemas)
> - [[Metodologias Ãgeis]] (GestÃ£o de Projetos)

## ğŸ¯ PadrÃ£o Unificador

```mermaid
graph LR
    A[Input/EstÃ­mulo] --> B[Feedback Loop]
    B --> C[AdaptaÃ§Ã£o Incremental]
    C --> D[EmergÃªncia de Robustez]
    D --> B
```

### Componentes Comuns

1. **Feedback Loops**
   - Neuro: Sinapses fortalecem/enfraquecem com uso
   - Sistemas: Auto-organizaÃ§Ã£o via retroalimentaÃ§Ã£o
   - Ãgil: Retrospectivas ajustam processos

2. **AdaptaÃ§Ã£o Incremental**
   - Neuro: MudanÃ§as sinÃ¡pticas graduais
   - Sistemas: Pequenas perturbaÃ§Ãµes testadas
   - Ãgil: Sprints curtos, melhorias iterativas

3. **Robustez por Diversidade**
   - Neuro: MÃºltiplas vias neurais (redundÃ¢ncia)
   - Sistemas: Diversidade de agentes
   - Ãgil: Times cross-funcionais

## ğŸ’¡ ImplicaÃ§Ãµes

### Nova Nota Sugerida
Criar: **[[Meta-PrincÃ­pio: EvoluÃ§Ã£o Adaptativa]]**

### ConexÃµes Reveladas
- [[Neuroplasticidade]] â†â†’ [[Metodologias Ãgeis]]
  (analogia estrutural nÃ£o Ã³bvia antes)

### AplicaÃ§Ãµes Emergentes
1. Usar princÃ­pios de neuroplasticidade em design de organizaÃ§Ãµes
2. Aplicar metodologias Ã¡geis em protocolos de reabilitaÃ§Ã£o neural

## ğŸ“Š ConfianÃ§a

- Similaridade estrutural: 87%
- Notas analisadas: 24
- DomÃ­nios envolvidos: 3
- Criado por: Sintetizador Agent (automÃ¡tico)
```

**POP do Sintetizador:**
```
ExecuÃ§Ã£o Semanal:
1. AnÃ¡lise de grafo (communities, centralidade)
2. DetecÃ§Ã£o de clusters densos (>8 notas, densidade >0.6)
3. Para cada cluster:
   a. Analisar temas comuns
   b. Sugerir MOC se nÃ£o existe
4. Cross-domain pattern matching
5. Gerar insights emergentes
6. Criar notas de sÃ­ntese

ValidaÃ§Ã£o:
âœ“ Insight Ã© realmente novo?
âœ“ Confidence > 70%?
âœ“ Aplicabilidade clara?
âœ“ Conecta 3+ domÃ­nios?
```

---

## ğŸ”„ WORKFLOWS COMPLETOS (POPs Integrados)

### Workflow 1: **Processar Paper AcadÃªmico**

**Input:** `cerebrum process paper.pdf`

**Athena (Orquestrador) executa:**

```yaml
workflow: process_academic_paper
steps:
  - agent: Extrator
    input: paper.pdf
    output: structured_text.json
    validation:
      - text_length > 1000
      - metadata.title exists

  - agent: Classificador
    input: structured_text.json
    output: framework_plan.json
    validation:
      - basb_path defined
      - templates selected

  - agent: Destilador
    input:
      - structured_text.json
      - framework_plan.json
    output: atomic_notes[]
    validation:
      - min_notes: 5
      - max_notes: 20
      - each_note_has_title

  - agent: Anatomista
    input: atomic_notes[]
    output: structured_notes[]
    validation:
      - frontmatter_valid
      - sections_complete

  - agent: Conector
    input: structured_notes[]
    output: linked_notes[]
    validation:
      - orphans == 0
      - avg_links >= 3

  - agent: Curador
    input: linked_notes[]
    output: health_report.md
    validation:
      - all_notes_saved
      - backups_created

  - agent: Sintetizador
    input: vault_updated
    output: insights[]
    validation:
      - optional (pode nÃ£o gerar insights)

final_output:
  - notes_created: 12
  - mocs_suggested: 2
  - links_created: 48
  - insights_generated: 1
  - time_elapsed: 2min 34s
```

**RelatÃ³rio Final (ATHENA):**
```markdown
# âœ… Processamento ConcluÃ­do

## ğŸ“„ Input
- **Arquivo:** Silva2024_Neuroplasticity.pdf
- **PÃ¡ginas:** 24
- **Palavras:** 8,420

## ğŸ¤– ExecuÃ§Ã£o

âœ… Extrator (12s)
  â†’ Texto extraÃ­do, 5 seÃ§Ãµes identificadas

âœ… Classificador (3s)
  â†’ Framework: BASB (Resources) + LYT (Neuro MOC) + Zettelkasten (Literature)
  â†’ Templates: academic-literature, concept

âœ… Destilador (1min 45s)
  â†’ 12 conceitos atÃ´micos identificados
  â†’ 1 literatura note criada

âœ… Anatomista (28s)
  â†’ Templates aplicados
  â†’ Progressive Summarization Layer 0 completo

âœ… Conector (38s)
  â†’ 48 links criados (avg 4/nota)
  â†’ 0 notas Ã³rfÃ£s
  â†’ 2 clusters detectados â†’ sugerir MOCs

âœ… Curador (8s)
  â†’ Health check: âœ… Verde
  â†’ PrÃ³ximas revisÃµes agendadas

âœ… Sintetizador (15s)
  â†’ 1 insight emergente detectado
  â†’ PadrÃ£o cross-domain: Neuroplasticidade â†” Sistemas Adaptativos

## ğŸ“ Output

### Notas Criadas (13)

**Literatura:**
1. [[Silva2024 - Neuroplasticity and Learning]]

**Conceitos:**
2. [[PotenciaÃ§Ã£o de Longo Prazo (LTP)]]
3. [[ConsolidaÃ§Ã£o de MemÃ³ria]]
4. [[Janelas CrÃ­ticas de Aprendizagem]]
5. [[Neuroplasticidade Dependente de ExperiÃªncia]]
6. [[Plasticidade SinÃ¡ptica]]
7. [[Receptores NMDA]]
8. [[Espinhas DendrÃ­ticas]]
9. [[Neurotransmissores Moduladores]]
10. [[Neuroplasticidade em Adultos]]
11. [[PerÃ­odo CrÃ­tico]]
12. [[Aprendizagem Motora]]
13. [[ReabilitaÃ§Ã£o Neural]]

### MOCs Sugeridos (2)
- Atualizar [[ğŸ§  Neuroscience MOC]] (11 notas adicionadas)
- Criar [[ğŸ“š Learning Mechanisms MOC]] (novo cluster)

### Insights Emergentes (1)
- [[ğŸ”® PadrÃ£o: Plasticidade como PrincÃ­pio Universal]]

## ğŸ”— Grafo Atualizado

```
Antes:  1,230 notas, 4,892 links
Depois: 1,243 notas, 4,940 links
Î”: +13 notas, +48 links
```

## ğŸ“Š Qualidade

| MÃ©trica | Valor | Target | Status |
|---------|-------|--------|--------|
| Notas Ã³rfÃ£s | 0/13 | 0% | âœ… |
| Links/nota | 4 | 3-8 | âœ… |
| Frontmatter | 13/13 | 100% | âœ… |
| Templates | 13/13 | 100% | âœ… |

## â±ï¸ Performance

- **Total:** 2min 34s
- **Mais lento:** Destilador (1min 45s - LLM calls)
- **Mais rÃ¡pido:** Classificador (3s)

## ğŸ¯ PrÃ³ximos Passos

1. Revisar [[Silva2024 - Neuroplasticity and Learning]] para Progressive Summarization Layer 1
2. Explorar insights emergentes
3. Considerar criar MOC de Learning Mechanisms

---

**Tudo salvo em:** `3-Resources/41-Neuroscience/`
**Abrir vault:** `cerebrum open`
```

---

### Workflow 2: **Daily Knowledge Refinement**

**Input:** `cerebrum daily`

**Athena executa:**

```yaml
workflow: daily_refinement
schedule: every_day_09:00

steps:
  - stage: inbox_processing
    agent: Classificador
    input: 00-Inbox/*
    action: classify_and_route

  - stage: linking
    agent: Conector
    input: notes_created_last_24h
    action: create_semantic_links

  - stage: health_check
    agent: Curador
    action: quick_health_scan

  - stage: review_reminder
    agent: Curador
    action: list_notes_due_today

output: daily_briefing.md
```

**Daily Briefing:**
```markdown
# ğŸ“… Daily Knowledge Briefing
*2025-01-15*

## ğŸ“¥ Inbox Processado

- 5 notas movidas para PARA
  - 2 â†’ Projects (Projeto X)
  - 1 â†’ Areas (Pesquisa)
  - 2 â†’ Resources (Filosofia)

## ğŸ”— Novos Links

- 12 conexÃµes criadas
- 2 notas anteriormente Ã³rfÃ£s agora conectadas

## ğŸ“Š Health Check

âœ… **Verde** - Sistema saudÃ¡vel
- Orphans: 1.2% (target <3%)
- Avg links: 4.6 (target 3-8)

## ğŸ“ RevisÃµes Agendadas Hoje

1. [[Conceito X]] (seedling â†’ budding)
2. [[Teoria Y]] (3Âª revisÃ£o, prÃ³ximo: evergreen)
3. [[Paper Z]] (Progressive Summary Layer 2)

**Tempo estimado:** 35 min

## ğŸ’¡ Dica do Dia

VocÃª tem 23 notas com Layer 0 que foram acessadas 5+ vezes.
Considere aplicar Progressive Summarization Layer 1.

---

**Comando rÃ¡pido:** `cerebrum review today`
```

---

### Workflow 3: **Weekly Knowledge Synthesis**

**Input:** `cerebrum weekly`

**Athena executa:**

```yaml
workflow: weekly_synthesis
schedule: every_sunday_18:00

steps:
  - stage: weekly_review
    agent: Curador
    action: comprehensive_health_check

  - stage: moc_suggestions
    agent: Conector
    action: detect_clusters_for_mocs

  - stage: insight_generation
    agent: Sintetizador
    action: analyze_weekly_patterns

  - stage: archive_completed
    agent: Curador
    action: move_completed_projects_to_archive

output: weekly_synthesis_report.md
```

---

## ğŸ“‹ TAXONOMIA PADRÃƒO UNIFICADA

### Estrutura de Tags HierÃ¡rquicos

```yaml
taxonomy:
  domains:
    neuroscience:
      - neuro/cellular
      - neuro/cognitive
      - neuro/developmental
      - neuro/clinical

    philosophy:
      - philo/epistemology
      - philo/metaphysics
      - philo/ethics
      - philo/logic

    systems:
      - systems/complex
      - systems/adaptive
      - systems/emergence

    methods:
      - methods/research
      - methods/analysis
      - methods/synthesis

  types:
    - concept/definition
    - concept/mechanism
    - concept/theory
    - concept/model

    - evidence/empirical
    - evidence/anecdotal
    - evidence/theoretical

    - application/practical
    - application/theoretical

  status:
    - status/seedling    # Nova, < 3 links, nÃ£o revisada
    - status/budding     # 3-5 links, 1-2 revisÃµes
    - status/evergreen   # 5+ links, 3+ revisÃµes, alta qualidade
    - status/crystallized # Central no grafo, altamente conectada

  basb:
    - basb/project       # Projeto ativo
    - basb/area          # Ãrea de responsabilidade
    - basb/resource      # Recurso de referÃªncia
    - basb/archive       # Arquivado

  lyt:
    - lyt/moc            # Map of Content
    - lyt/home           # Home note
    - lyt/index          # Index note

  zettelkasten:
    - zk/fleeting        # Ideia rÃ¡pida (<24h)
    - zk/literature      # Nota de fonte
    - zk/permanent       # Nota evergreen
    - zk/hub             # Nota central
```

### Frontmatter PadrÃ£o Completo

```yaml
---
# IdentificaÃ§Ã£o
id: 20250115143022           # Timestamp Ãºnico
title: "TÃ­tulo SemÃ¢ntico"
aliases: ["Alternativa 1", "AbreviaÃ§Ã£o"]

# ClassificaÃ§Ã£o
type: permanent              # fleeting, literature, permanent, moc, project
status: seedling             # seedling, budding, evergreen, crystallized
domain: neuroscience
subdomain: cellular
tags:
  - neuro/cellular
  - concept/mechanism
  - evidence/empirical

# BASB
basb:
  para: "3-Resources/41-Neuroscience"
  progressive_summary:
    layer: 0               # 0-4
    last_summarized: null
  intermediate_packet: false

# LYT
lyt:
  mocs:
    - "Neuroscience MOC"
    - "Learning MOC"
  fluid_framework: "Science-Philosophy Bridge"

# Zettelkasten
zettelkasten:
  connections_count: 0       # Atualizado automaticamente
  centrality_score: 0.0      # PageRank no grafo
  cluster_id: null

# Metadata
source:
  type: academic_paper       # book, article, video, podcast, course
  title: "Silva2024_Neuroplasticity"
  authors: ["Silva, M.", "Costa, P."]
  year: 2024
  doi: "10.1038/nn.2024.123"
  url: null

# GestÃ£o
created: 2025-01-15T14:30:22
modified: 2025-01-15T14:30:22
reviewed: 0                  # Contagem de revisÃµes
last_reviewed: null
next_review: 2025-01-22      # Spaced repetition
version: 1

# Qualidade
confidence: 0.75             # 0.0-1.0
completeness: 0.6            # 0.0-1.0
importance: medium           # low, medium, high, critical

# PENSE Framework
pense:
  precisao: "DefiniÃ§Ã£o clara e validada"
  estrutura: "Seguindo template concept-academic"
  natureza: "Contexto brasileiro considerado"
  sistematizacao: "Processo replicÃ¡vel aplicado"
  experimentacao: "VersÃ£o 1, aguardando feedback"
---
```

---

## ğŸ“ GUIDELINES DE CURADORIA

### 1. Atomicidade (Zettelkasten)

**Regra:** 1 nota = 1 conceito completo

âœ… **BOM:**
```
# PotenciaÃ§Ã£o de Longo Prazo (LTP)

LTP Ã© o fortalecimento duradouro de sinapses...
[ExplicaÃ§Ã£o completa do conceito]
```

âŒ **RUIM:**
```
# Plasticidade SinÃ¡ptica

LTP Ã©... LTD Ã©... Homeostase sinÃ¡ptica Ã©...
[VÃ¡rios conceitos misturados]
```

**CorreÃ§Ã£o:** Quebrar em 3 notas separadas

---

### 2. Autonomia (Standalone)

**Regra:** Nota deve fazer sentido sozinha

âœ… **BOM:**
```
# Receptores NMDA

> [!abstract] DefiniÃ§Ã£o
> Receptores NMDA sÃ£o canais iÃ´nicos ativados por glutamato
> que permitem influxo de CaÂ²âº quando despolarizaÃ§Ã£o remove
> bloqueio de MgÂ²âº...
```

âŒ **RUIM:**
```
# Receptores NMDA

Como visto anteriormente, esses receptores...
[Assume conhecimento da nota anterior]
```

---

### 3. Conectividade (Linking)

**Regra:** 3-8 links por nota

âœ… **BOM:**
```
## ConexÃµes

### Fundamenta
- [[LTP]] - NMDA Ã© essencial para LTP
- [[Aprendizagem]] - NMDA crÃ­tico para memÃ³ria

### Requer
- [[Glutamato]] - Ligante necessÃ¡rio
- [[DespolarizaÃ§Ã£o]] - Remove bloqueio MgÂ²âº

### Relacionados
- [[Receptores AMPA]] - Co-localizaÃ§Ã£o sinÃ¡ptica
```

âŒ **RUIM:**
```
Links: [[A]], [[B]], [[C]], [[D]], [[E]], [[F]], [[G]], [[H]], [[I]], [[J]]...
[Links demais, sem contexto]
```

---

### 4. Progressive Summarization (BASB)

**Regra:** Destile em camadas ao longo do tempo

**Layer 0** (Captura):
```
[Texto completo copiado da fonte]
```

**Layer 1** (Primeiro uso - negrito 10-20%):
```
Neuroplasticidade Ã© a **capacidade do cÃ©rebro de reorganizar
estrutura e funÃ§Ã£o** ao longo da vida. Isso ocorre atravÃ©s de
**fortalecimento ou enfraquecimento de sinapses** (LTP/LTD),
**crescimento de novos neurÃ´nios** (neurogÃªnese), e **formaÃ§Ã£o
de novas conexÃµes** (sinaptogÃªnese).
```

**Layer 2** (Uso crÃ­tico - highlight 10-20% dos negritos):
```
Neuroplasticidade Ã© a ==**capacidade do cÃ©rebro de reorganizar
estrutura e funÃ§Ã£o**== ao longo da vida. Isso ocorre atravÃ©s de
**fortalecimento ou enfraquecimento de sinapses** (LTP/LTD),
**crescimento de novos neurÃ´nios** (neurogÃªnese), e ==**formaÃ§Ã£o
de novas conexÃµes**== (sinaptogÃªnese).
```

**Layer 3** (Nota central - executive summary no topo):
```
> [!summary] Executive Summary
> Neuroplasticidade = reorganizaÃ§Ã£o estrutural/funcional do cÃ©rebro
> via LTP/LTD, neurogÃªnese e sinaptogÃªnese. Fundamental para
> aprendizagem, memÃ³ria e recuperaÃ§Ã£o de lesÃµes.

[Layer 2 completo abaixo]
```

---

### 5. Taxonomia Consistente

**Regra:** Use tags hierÃ¡rquicos padronizados

âœ… **BOM:**
```yaml
tags:
  - neuro/cellular
  - concept/mechanism
  - evidence/empirical
```

âŒ **RUIM:**
```yaml
tags:
  - neurociencia
  - mecanismo celular
  - comprovado
  - importante
  - revisar
```

---

## ğŸš¦ CHECKLISTS DE VALIDAÃ‡ÃƒO

### Checklist: Nota AtÃ´mica Perfeita

```markdown
## âœ… ValidaÃ§Ã£o de Nota AtÃ´mica

### Estrutura
- [ ] Frontmatter completo e vÃ¡lido
- [ ] TÃ­tulo semÃ¢ntico claro
- [ ] ID Ãºnico presente
- [ ] Tags hierÃ¡rquicos corretos

### ConteÃºdo
- [ ] 1 conceito = 1 nota (atomicidade)
- [ ] Nota faz sentido sozinha (autonomia)
- [ ] DefiniÃ§Ã£o clara no inÃ­cio
- [ ] Exemplos quando aplicÃ¡vel
- [ ] Contexto fornecido

### ConexÃµes
- [ ] 3-8 links para outras notas
- [ ] Links tipados (supports, extends, etc.)
- [ ] Backlinks verificados
- [ ] MOCs relevantes referenciados

### BASB
- [ ] PARA path correto
- [ ] Progressive Summary layer definido
- [ ] Source citado corretamente

### LYT
- [ ] MOC relevante existe/criado
- [ ] Conectado a framework fluido

### Zettelkasten
- [ ] Tipo correto (fleeting/literature/permanent)
- [ ] Status adequado (seedling/budding/evergreen)

### Qualidade
- [ ] Markdown vÃ¡lido
- [ ] Sem erros de ortografia
- [ ] Callouts usados apropriadamente
- [ ] Confidence score justificado
```

---

### Checklist: Health do Vault

```markdown
## âœ… ValidaÃ§Ã£o de SaÃºde do Vault

### MÃ©tricas Gerais
- [ ] Orphan rate < 3%
- [ ] Avg links per note: 3-8
- [ ] Graph density > 0.3
- [ ] Duplicates < 1%

### DistribuiÃ§Ã£o de Status
- [ ] Seedling: ~50-60%
- [ ] Budding: ~25-35%
- [ ] Evergreen: ~10-20%
- [ ] Crystallized: ~1-5%

### Progressive Summarization
- [ ] Layer 1: ~30% das notas
- [ ] Layer 2: ~10% das notas
- [ ] Layer 3: ~2% das notas

### BASB PARA
- [ ] Projects: apenas ativos
- [ ] Archives: projetos completos movidos
- [ ] Inbox: processado semanalmente

### LYT
- [ ] MOCs cobrem principais domÃ­nios
- [ ] Home note atualizado
- [ ] Fluid frameworks funcionais

### ManutenÃ§Ã£o
- [ ] Backups automÃ¡ticos ativos
- [ ] Git commits regulares
- [ ] Spaced repetition agendado
- [ ] Stale notes < 10%
```

---

## ğŸ“ PRÃ“XIMOS PASSOS DE IMPLEMENTAÃ‡ÃƒO

Esta visÃ£o Ã© massiva. Vou criar nos prÃ³ximos documentos:

1. **FRAMEWORKS_INTEGRATION.md** - Detalhes de como BASB, LYT, Zettelkasten se integram tecnicamente
2. **ORCHESTRATION_POPS.md** - POPs detalhados de cada agente com cÃ³digo
3. **IMPLEMENTATION_PHASES.md** - Como implementar isso em 6 meses
4. **TAXONOMY_GUIDE.md** - Guia completo da taxonomia unificada

**Quer que eu crie qual primeiro?**
