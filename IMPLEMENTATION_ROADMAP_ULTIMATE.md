# üó∫Ô∏è Roadmap de Implementa√ß√£o - Cerebrum Ultimate

> **"De MVP funcional a refinaria suprema em 6 meses"**

---

## üéØ VIS√ÉO GERAL

**Meta:** Implementar progressivamente o sistema multi-agente completo, validando cada fase antes de avan√ßar.

**Filosofia:** Start simple, validate, iterate, expand

---

## üìÖ CRONOGRAMA MACRO (6 Meses)

```
M√™s 1: MVP Funcional (Destilador + Classificador)
M√™s 2: Linking Inteligente (Conector)
M√™s 3: Curadoria Autom√°tica (Curador)
M√™s 4: Orquestra√ß√£o Completa (Athena)
M√™s 5: Insights Emergentes (Sintetizador)
M√™s 6: Polish + Otimiza√ß√£o
```

---

## üèóÔ∏è FASE 1: MVP FUNCIONAL (Semanas 1-4)

### Objetivo
Sistema b√°sico que pega PDF/texto e gera notas at√¥micas estruturadas.

### Agentes a Implementar
- ‚úÖ **Extrator** (b√°sico - PDF + Markdown)
- ‚úÖ **Classificador** (heur√≠stico simples)
- ‚úÖ **Destilador** (LLM local)

### Features
- [x] CLI funcional (`cerebrum process file.pdf`)
- [x] Extra√ß√£o de PDF
- [x] Classifica√ß√£o de conte√∫do (academic_paper vs fleeting)
- [x] Gera√ß√£o de notas at√¥micas (5-12 por documento)
- [x] Frontmatter b√°sico (id, title, type, domain, tags)
- [x] Salvar em estrutura PARA

### Deliverables

**Semana 1-2: Extrator + Classificador**

```bash
# Dia 1-3: Extrator
- Implementar ExtratorAgent
- Parser PDF (pypdf)
- Parser Markdown (python-frontmatter)
- Metadata extraction
- Testes: 5 PDFs acad√™micos

# Dia 4-7: Classificador
- Implementar ClassificadorAgent
- Heur√≠sticas de classifica√ß√£o
- Framework plan b√°sico (BASB + Zettelkasten)
- Taxonomia por keywords
- Testes: 10 documentos variados
```

**Semana 3-4: Destilador**

```bash
# Dia 8-14: Destilador
- Implementar DestiladorAgent
- LLM prompt para conceitos at√¥micos
- Template concept-basic
- Gera√ß√£o de frontmatter
- Slugification
- Save to vault
- Testes: Processar 20 papers

# Dia 14: Valida√ß√£o Phase 1
- [ ] Processar 1 paper acad√™mico em <3 min
- [ ] Gerar 5-10 notas at√¥micas
- [ ] Frontmatter completo e v√°lido
- [ ] Salvo na estrutura PARA correta
- [ ] Usar em seu pr√≥prio vault por 1 semana
```

### C√≥digo Essencial

```python
# cerebrum/agents/phase1_mvp.py

class Phase1Pipeline:
    """MVP: Extrator ‚Üí Classificador ‚Üí Destilador"""

    def __init__(self):
        self.extrator = ExtratorAgent()
        self.classificador = ClassificadorAgent()
        self.destilador = DestiladorAgent()

    def process(self, file_path: str) -> Dict:
        # Step 1: Extract
        extracted = self.extrator.process({'file_path': file_path})
        if not extracted['validation']['passed']:
            raise Exception("Extra√ß√£o falhou")

        # Step 2: Classify
        classified = self.classificador.process(extracted['output'])
        if not classified['validation']['passed']:
            raise Exception("Classifica√ß√£o falhou")

        # Step 3: Distill
        distilled = self.destilador.process({
            **extracted['output'],
            **classified['output']
        })
        if not distilled['validation']['passed']:
            raise Exception("Destila√ß√£o falhou")

        # Save notes
        notes_saved = []
        for note in distilled['output']['notes']:
            filepath = self._save_note(note)
            notes_saved.append(filepath)

        return {
            'notes_created': len(notes_saved),
            'paths': notes_saved
        }
```

### Success Criteria - Phase 1

- ‚úÖ 20 papers processados com sucesso
- ‚úÖ Tempo m√©dio < 3 min/paper
- ‚úÖ 0 erros de frontmatter
- ‚úÖ Notas fazem sentido standalone
- ‚úÖ Voc√™ usa o sistema diariamente

---

## üîó FASE 2: LINKING INTELIGENTE (Semanas 5-8)

### Objetivo
Notas n√£o ficam √≥rf√£s - sistema cria conex√µes sem√¢nticas autom√°ticas.

### Agente a Implementar
- ‚úÖ **Conector** (embeddings + LLM)

### Features
- [ ] Gerar embeddings de cada nota (ChromaDB)
- [ ] Busca por similaridade sem√¢ntica
- [ ] LLM para validar conex√µes
- [ ] Tipos de links (supports, extends, etc.)
- [ ] Backlinks autom√°ticos
- [ ] Detec√ß√£o de clusters ‚Üí sugest√£o de MOCs

### Deliverables

**Semana 5-6: Embeddings & Search**

```bash
# Setup
pip install chromadb sentence-transformers

# Implementa√ß√£o
- ChromaDB setup
- Embedding generation (all-MiniLM-L6-v2)
- Similarity search (threshold 0.75)
- Cache de embeddings
- Testes: 100 notas, buscar similares
```

**Semana 7-8: Link Creation & Validation**

```bash
# Implementa√ß√£o
- LLM prompt para validar links
- Tipos de relacionamento
- Bidirectional linking
- Update frontmatter (links_out, links_in)
- Graph analysis b√°sico (NetworkX)
- Cluster detection (Louvain)
- Testes: 50 notas novas, linkar ao vault existente
```

### C√≥digo Essencial

```python
# cerebrum/agents/conector.py

class ConectorAgent:
    def __init__(self):
        self.chroma_client = chromadb.Client()
        self.collection = self.chroma_client.get_or_create_collection("notes")
        self.llm = LLMService()

    def process(self, input_msg: Dict) -> Dict:
        new_notes = input_msg['notes']
        vault_path = input_msg['vault_path']

        # Load existing vault
        existing_notes = self._load_vault_notes(vault_path)

        results = []

        for new_note in new_notes:
            # Generate embedding
            embedding = self._generate_embedding(new_note['content'])

            # Search similar
            similar = self.collection.query(
                query_embeddings=[embedding],
                n_results=15,
                where={"type": "permanent"}
            )

            # LLM validation
            validated_links = []
            for candidate in similar['documents'][0]:
                should_link = self._llm_validate_link(new_note, candidate)

                if should_link['link']:
                    validated_links.append({
                        'target': candidate['slug'],
                        'type': should_link['type'],
                        'confidence': should_link['confidence']
                    })

            # Update note
            new_note['metadata']['links_out'] = validated_links

            # Update backlinks in targets
            for link in validated_links:
                self._add_backlink(link['target'], new_note['slug'])

            results.append(new_note)

        # Detect clusters
        clusters = self._detect_clusters(results + existing_notes)

        return {
            'output': {
                'linked_notes': results,
                'clusters': clusters
            },
            'validation': self._validate_linking(results)
        }
```

### Success Criteria - Phase 2

- ‚úÖ 0% notas √≥rf√£s
- ‚úÖ M√©dia 4-6 links/nota
- ‚úÖ Links fazem sentido contextualmente
- ‚úÖ 2-3 clusters detectados ‚Üí MOCs sugeridos
- ‚úÖ Tempo de linking < 30s/nota

---

## üßπ FASE 3: CURADORIA AUTOM√ÅTICA (Semanas 9-12)

### Objetivo
Sistema mant√©m sa√∫de do vault automaticamente.

### Agente a Implementar
- ‚úÖ **Curador**

### Features
- [ ] Health checks di√°rios/semanais/mensais
- [ ] Detec√ß√£o de √≥rf√£os e duplicatas
- [ ] Spaced repetition scheduling
- [ ] Status evolution (seedling ‚Üí evergreen)
- [ ] Progressive Summarization tracking
- [ ] Dashboard de m√©tricas

### Deliverables

**Semana 9-10: Health Checks**

```python
# cerebrum/agents/curador.py

class CuradorAgent:
    def daily_check(self):
        """Execu√ß√£o di√°ria (5 min)"""
        # Scan notas criadas hoje
        # Validar frontmatter
        # Verificar orphans imediatos
        # Agendar pr√≥ximas revis√µes
        pass

    def weekly_check(self):
        """Execu√ß√£o semanal (20 min)"""
        # Gerar health report
        # Detectar duplicatas
        # Evoluir status de notas
        # Sugerir MOCs para clusters
        pass

    def monthly_check(self):
        """Execu√ß√£o mensal (60 min)"""
        # Dashboard completo
        # An√°lise de tend√™ncias
        # Limpeza de archives
        # Otimiza√ß√£o de taxonomia
        pass
```

**Semana 11-12: Automation & Dashboard**

```bash
# Implementa√ß√£o
- Cron-like scheduler (APScheduler)
- Automated reviews reminder
- Dashboard generation (Markdown)
- Dataview queries integration
- Backup automation
- Testes: rodar em vault de 500+ notas
```

### Success Criteria - Phase 3

- ‚úÖ Health check roda automaticamente
- ‚úÖ Dashboard atualiza semanalmente
- ‚úÖ Spaced repetition funciona
- ‚úÖ Orphans < 3% sempre
- ‚úÖ Status evolui automaticamente

---

## üéº FASE 4: ORQUESTRA√á√ÉO COMPLETA (Semanas 13-16)

### Objetivo
Athena orquestra todos os agentes em workflows robustos.

### Componente a Implementar
- ‚úÖ **Athena Orchestrator**
- ‚úÖ **Anatomista** (templates avan√ßados)

### Features
- [ ] Pipeline declarativo (YAML workflows)
- [ ] Valida√ß√£o entre etapas
- [ ] Rollback em caso de falha
- [ ] Logs estruturados
- [ ] M√©tricas de performance
- [ ] Templates din√¢micos avan√ßados

### Deliverables

**Semana 13-14: Orchestrator Core**

```yaml
# workflows/process_paper.yaml

name: process_academic_paper
description: Processa paper acad√™mico completo

steps:
  - agent: Extrator
    input: {file_path: $INPUT}
    validation:
      - text_length > 1000
      - metadata.title exists

  - agent: Classificador
    input: {raw_text: $PREV.raw_text, metadata: $PREV.metadata}
    validation:
      - basb_path defined

  - agent: Destilador
    input: {raw_text: $STEP1.raw_text, framework_plan: $PREV.framework_plan}
    validation:
      - min_notes >= 5

  - agent: Anatomista
    input: {notes: $PREV.notes, templates: $STEP2.templates}

  - agent: Conector
    input: {notes: $PREV.structured_notes}

  - agent: Curador
    input: {new_notes: $PREV.linked_notes}

output: final_report.md
```

```python
class AthenaOrchestrator:
    def load_workflow(self, yaml_path: str):
        """Carrega workflow de arquivo YAML"""
        pass

    def execute_workflow(self, workflow: Dict, input_data: Dict):
        """Executa workflow com valida√ß√£o em cada etapa"""
        pass
```

**Semana 15-16: Anatomista & Templates**

```bash
# Implementa√ß√£o
- Template engine avan√ßado
- Templates por tipo de conte√∫do
- Callouts din√¢micos
- Mermaid diagrams auto-generation
- Dataview queries embedding
- Testes: 10 tipos diferentes de notas
```

### Success Criteria - Phase 4

- ‚úÖ Pipeline completo end-to-end funciona
- ‚úÖ Valida√ß√£o detecta e reporta erros
- ‚úÖ Logs permitem debug
- ‚úÖ Templates cobrem 80% dos casos
- ‚úÖ Tempo total < 5 min para paper completo

---

## üîÆ FASE 5: INSIGHTS EMERGENTES (Semanas 17-20)

### Objetivo
Sistema detecta padr√µes e gera conhecimento novo.

### Agente a Implementar
- ‚úÖ **Sintetizador**

### Features
- [ ] Community detection (graph clustering)
- [ ] Cross-domain pattern matching
- [ ] Analogical reasoning (estruturas similares)
- [ ] Insight generation (notas s√≠ntese)
- [ ] Auto-create MOCs para clusters
- [ ] Trend analysis

### Deliverables

**Semana 17-18: Graph Analysis**

```python
# cerebrum/agents/sintetizador.py

class SintetizadorAgent:
    def detect_communities(self, graph: nx.Graph):
        """Louvain algorithm para clustering"""
        communities = community_louvain.best_partition(graph)
        return communities

    def cross_domain_patterns(self, domains: List[str]):
        """Encontra padr√µes estruturais em dom√≠nios diferentes"""
        patterns = []

        for domain_a in domains:
            for domain_b in domains:
                if domain_a != domain_b:
                    similarity = self._structural_similarity(domain_a, domain_b)

                    if similarity > 0.75:
                        pattern = self._extract_pattern(domain_a, domain_b)
                        patterns.append(pattern)

        return patterns
```

**Semana 19-20: Insight Generation**

```bash
# Implementa√ß√£o
- LLM prompts para insights
- Nota synthesis template
- Auto-linking de insights a notas fonte
- Weekly insights report
- Testes: 1000+ notas vault, gerar insights
```

### Success Criteria - Phase 5

- ‚úÖ 1-3 insights emergentes/semana
- ‚úÖ Insights s√£o realmente n√£o-√≥bvios
- ‚úÖ Patterns cross-domain detectados
- ‚úÖ MOCs autom√°ticos criados
- ‚úÖ Voc√™ teve pelo menos 1 "aha moment"

---

## üíé FASE 6: POLISH & OTIMIZA√á√ÉO (Semanas 21-24)

### Objetivo
Sistema production-ready, otimizado, documentado.

### Features
- [ ] Performance optimization (cache, batch processing)
- [ ] Error handling robusto
- [ ] Retry logic com exponential backoff
- [ ] Configura√ß√£o flex√≠vel (YAML)
- [ ] Documenta√ß√£o completa
- [ ] Tests automatizados (pytest)
- [ ] CI/CD b√°sico

### Deliverables

**Semana 21: Performance**

```bash
- Implementar cache de embeddings (Redis ou SQLite)
- Batch processing (processar 10+ arquivos de uma vez)
- Lazy loading de grafo
- Otimizar prompts LLM (reduzir tokens)
- Benchmark: processar 100 papers em <30 min
```

**Semana 22: Robustez**

```bash
- Error handling em cada agente
- Retry logic para LLM calls
- Validation schemas (JSON Schema)
- Fallbacks quando LLM falha
- Graceful degradation
```

**Semana 23: Testes**

```bash
# tests/test_agents.py

def test_extrator_pdf():
    agent = ExtratorAgent()
    result = agent.process({'file_path': 'test.pdf'})
    assert result['validation']['passed']
    assert len(result['output']['raw_text']) > 100

def test_destilador_creates_notes():
    agent = DestiladorAgent()
    result = agent.process({...})
    assert len(result['output']['notes']) >= 5

# Coverage goal: >80%
```

**Semana 24: Documenta√ß√£o & Exemplos**

```bash
- README.md completo
- QUICKSTART.md atualizado
- Exemplos de uso
- Video tutorial (opcional)
- Deploy guide
```

### Success Criteria - Phase 6

- ‚úÖ 100 papers processados sem erros
- ‚úÖ Test coverage > 80%
- ‚úÖ Performance benchmarks atingidos
- ‚úÖ Documenta√ß√£o completa
- ‚úÖ 3+ pessoas testaram e aprovaram

---

## üìä M√âTRICAS DE PROGRESSO

### Por Fase

| Fase | Notas Criadas | Links Criados | Insights | Vault Health |
|------|---------------|---------------|----------|--------------|
| 1 | 100-200 | 0 | 0 | N/A |
| 2 | 300-500 | 800-1500 | 0 | 70% |
| 3 | 500-800 | 1500-3000 | 0 | 85% |
| 4 | 800-1200 | 3000-5000 | 0 | 90% |
| 5 | 1200-2000 | 5000-8000 | 5-10 | 92% |
| 6 | 2000+ | 8000+ | 10+ | 95% |

### KPIs Finais (M√™s 6)

**Performance:**
- ‚ö° Processar paper em <3 min
- ‚ö° Linking em <30s/nota
- ‚ö° Health check em <5 min
- ‚ö° 100 papers batch em <30 min

**Qualidade:**
- üìä Orphan rate < 2%
- üìä Avg links: 4-6/nota
- üìä Evergreen ratio: 15-20%
- üìä User satisfaction: 8+/10

**Escalabilidade:**
- üìà Vault de 2000+ notas
- üìà 8000+ links
- üìà 50+ MOCs
- üìà Sem degrada√ß√£o de performance

---

## üõ†Ô∏è TECH STACK FINAL

### Backend
```python
# Core
python = "^3.11"
fastapi = "^0.104.0"
pydantic = "^2.5.0"

# LLM & Embeddings
ollama = "^0.1.6"
sentence-transformers = "^2.2.2"
chromadb = "^0.4.18"

# Graph & Analysis
networkx = "^3.2"
python-louvain = "^0.16"

# Utilities
python-frontmatter = "^1.0.0"
pypdf = "^3.17.0"
pyyaml = "^6.0.1"
click = "^8.1.7"
rich = "^13.7.0"
apscheduler = "^3.10.4"

# Testing
pytest = "^7.4.3"
pytest-cov = "^4.1.0"
```

### Frontend (Opcional - Fase Extra)
```typescript
// Se quiser interface web
react = "^19.1.1"
vite = "^6.2.0"
reactflow = "^11.10.0"  // Graph viz
```

---

## üéØ MILESTONES PRINCIPAIS

### M√™s 1 ‚úÖ
**MVP Funcional**
- Processar 20 papers
- Gerar 200+ notas at√¥micas
- Usar no dia-a-dia

### M√™s 2 ‚úÖ
**Linking Inteligente**
- 0 √≥rf√£s
- 800+ links criados
- Primeiros MOCs sugeridos

### M√™s 3 ‚úÖ
**Curadoria Autom√°tica**
- Health checks rodando
- Dashboard atualizado
- Spaced repetition ativo

### M√™s 4 ‚úÖ
**Orquestra√ß√£o Completa**
- Pipeline end-to-end
- Templates avan√ßados
- <5 min processamento

### M√™s 5 ‚úÖ
**Insights Emergentes**
- Primeiros insights cross-domain
- MOCs autom√°ticos
- Sistema "pensa" junto

### M√™s 6 ‚úÖ
**Production Ready**
- Vault de 2000+ notas
- Performance otimizado
- Documentado e testado

---

## üö¶ DECIS√ïES CR√çTICAS

### Decis√£o 1: Local vs Cloud LLM
**Op√ß√£o A:** Local (Ollama)
- ‚úÖ Privacidade total
- ‚úÖ Custo zero
- ‚ùå Qualidade inferior
- ‚ùå Requer GPU

**Op√ß√£o B:** Cloud (Gemini)
- ‚úÖ Melhor qualidade
- ‚úÖ Mais r√°pido
- ‚ùå Custo por uso
- ‚ùå Privacidade

**Recomenda√ß√£o:** Hybrid
- Local para tarefas simples (classifica√ß√£o, linking)
- Cloud para tarefas complexas (gera√ß√£o de conte√∫do)

### Decis√£o 2: Vector DB
**Op√ß√£o A:** ChromaDB (local)
- ‚úÖ Simples setup
- ‚úÖ Local-first
- ‚ùå Escalabilidade limitada

**Op√ß√£o B:** Pinecone (cloud)
- ‚úÖ Escal√°vel
- ‚úÖ Managed
- ‚ùå Custo
- ‚ùå Depend√™ncia externa

**Recomenda√ß√£o:** ChromaDB para MVP, avaliar Pinecone se >10k notas

### Decis√£o 3: Interface
**Op√ß√£o A:** CLI puro
- ‚úÖ R√°pido
- ‚úÖ Script√°vel
- ‚ùå Learning curve

**Op√ß√£o B:** Web UI
- ‚úÖ User-friendly
- ‚úÖ Graph viz
- ‚ùå Complexidade

**Op√ß√£o C:** Obsidian Plugin
- ‚úÖ Integra√ß√£o nativa
- ‚úÖ Usa UI existente
- ‚ùå Limita√ß√µes da API

**Recomenda√ß√£o:** CLI + Web UI opcional (Fase 7)

---

## üìÖ PR√ìXIMOS 7 DIAS (Come√ßar AGORA)

### Dia 1 (Hoje)
```bash
# Setup
- [ ] Criar branch feature/cerebrum-ultimate
- [ ] Setup ambiente virtual
- [ ] Instalar depend√™ncias base
- [ ] Escrever primeiro teste

# Implementar
- [ ] ExtratorAgent skeleton
- [ ] Parser PDF b√°sico
- [ ] Teste com 1 PDF
```

### Dia 2
```bash
- [ ] Completar ExtratorAgent
- [ ] Metadata extraction
- [ ] Structure analysis
- [ ] Testes: 5 PDFs
```

### Dia 3
```bash
- [ ] ClassificadorAgent skeleton
- [ ] Content type detection
- [ ] Framework plan b√°sico
- [ ] Testes: 10 documentos
```

### Dia 4-5
```bash
- [ ] DestiladorAgent skeleton
- [ ] LLM integration (Ollama)
- [ ] Concept identification
- [ ] Note generation
- [ ] Testes: 3 papers
```

### Dia 6-7
```bash
- [ ] Integra√ß√£o Extrator ‚Üí Classificador ‚Üí Destilador
- [ ] CLI command: cerebrum process
- [ ] End-to-end test: processar 1 paper completo
- [ ] Validar output no Obsidian
- [ ] Ajustes baseados em feedback
```

---

## üéì LI√á√ïES APRENDIDAS (Antecipadas)

### Armadilhas a Evitar

1. **Over-engineering inicial**
   - N√£o implemente todos agentes de uma vez
   - Valide cada fase antes de avan√ßar

2. **Perfeccionismo de prompts**
   - Prompts LLM nunca ser√£o perfeitos
   - Itere baseado em uso real

3. **Subestimar valida√ß√£o**
   - Valida√ß√£o entre agentes √© CR√çTICA
   - Invista tempo nisso

4. **Ignorar performance cedo**
   - Cache embeddings desde o in√≠cio
   - Batch processing > loop individual

5. **Documenta√ß√£o depois**
   - Documente enquanto implementa
   - Futuro voc√™ agradece

---

## ‚úÖ CHECKLIST DE SUCESSO

### Fase 1 Completa Quando:
- [ ] 20 papers processados
- [ ] 200+ notas criadas
- [ ] Voc√™ usa diariamente
- [ ] Amigo testou e funcionou

### Fase 2 Completa Quando:
- [ ] Linking autom√°tico funciona
- [ ] 0 √≥rf√£s
- [ ] Conex√µes fazem sentido
- [ ] MOC sugerido e criado

### Sistema Completo Quando:
- [ ] Vault de 2000+ notas
- [ ] Performance benchmarks OK
- [ ] Testes passam
- [ ] Documenta√ß√£o completa
- [ ] 3+ pessoas usando com sucesso
- [ ] Voc√™ n√£o imagina vida sem

---

**Come√ßar agora:** Abra terminal e rode primeiro comando! üöÄ
